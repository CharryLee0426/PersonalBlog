---
title: 优化问题
date: 2020-01-28
tags: 数模笔记
categories: 数学建模
mathjax: true
top: false
---

### <center>利用SciPy和SymPy求解优化问题</center>

我们可以利用SciPy中的optimize模块解决非线性优化问题，优化库cvxopt还可以处理带线性约束的线性优化问题和二次规划问题的求解器

优化问题大体可以分成以下几个问题：
- 单变量优化
- 多变量优化
- 线性优化
- 非线性优化
- 线性约束
- 非线性约束

首先导入包。同样的我们必须先做一些配置。


```python
import numpy as np
import sympy
import matplotlib.pyplot as plt
from scipy import optimize as op
import cvxopt
%matplotlib inline
%config InlineBackend.figure_format='jpg'
```

首先先看单变量优化问题，注意，下面的讨论的基础是目标函数和约束函数均是连续光滑的，且参数取值连续，否则下述很多方法将会不适用。

解下述经点的单变量优化问题
$$
\min \qquad f(r,h)=2\pi r^2 + 2\pi r h \\
s.t. \qquad V=\pi r^2h = 1
$$


```python
r,h = sympy.symbols('r,h')
Area = 2 * sympy.pi * r**2 + 2 * sympy.pi * r * h
Volume = sympy.pi * r**2 * h
h_r = sympy.solve(Volume - 1, h)[0]
Area_r = Area.subs(h,h_r)
rsol = sympy.solve(Area_r.diff(r))[0]
rsol
```




$\displaystyle \frac{2^{\frac{2}{3}}}{2 \sqrt[3]{\pi}}$




```python
_.evalf()
```




$\displaystyle 0.541926070139289$



一般符号求解只适用于比较简单的问题，对于复杂问题必须使用数值方法。下面用数值方法解决上述问题。


```python
f = lambda x: 2 * np.pi * x**2 + 2 / x
r_min = op.brent(f,brack=(0.1,4))
print(r_min)
print(f(r_min))
```

    0.5419260772557135
    5.535810445932086


也可以使用通用接口minimize_scalar，指明区间时应该使用bracket。


```python
op.minimize_scalar(f,bracket=(0.1,4))
```




         fun: 5.535810445932086
        nfev: 19
         nit: 15
     success: True
           x: 0.5419260772557135



通常寻找bracket区间前可以进行可视化，可以更方便我们寻找区间范围。


```python
x = np.linspace(0.1,2,5000)
y = f(x)
x_fit = op.minimize_scalar(f,bracket=(0.1,4))['x']
y_fit = op.minimize_scalar(f,bracket=(0.1,4))['fun']
fig, ax = plt.subplots(figsize=(12,4))
ax.plot(x,y, 'k', lw=1.5)
ax.plot(x_fit,y_fit, 'r*', markersize=15)
ax.set_xlabel(r'$r$',fontsize=18)
ax.set_ylim(0,30)
ax.annotate('The best fit point we found',fontsize=12,xy=(x_fit,y_fit),xytext = (+0.2,+15),
            arrowprops=dict(arrowstyle='->',linewidth=1,connectionstyle='arc3,rad=-.6'))
ax.set_title(r'$f(x)=2\pi r^2+2/r$',color='grey',fontsize=20)
fig.savefig('danbianliang.pdf')
```


​    
![](https://img.imgdb.cn/item/6011add63ffa7d37b35cee92.jpg)
​    


下面我们考虑无约束的多变量优化问题
$$
\min f(x_1,x_2)=(x_1 - 1)^4+5(x_2-1)^2 -2x_1x_2
$$


```python
x1,x2 = sympy.symbols('x_1,x_2')
f_sym = (x1 - 1)**4 + 5 * (x2 - 1)**2 - 2 * x1 * x2
fprime_sym = [f_sym.diff(x_) for x_ in (x1,x2)]
sympy.Matrix(fprime_sym)
```




$\displaystyle \left[\begin{matrix}- 2 x_{2} + 4 \left(x_{1} - 1\right)^{3}\\- 2 x_{1} + 10 x_{2} - 10\end{matrix}\right]$




```python
fhess_sym = [[f_sym.diff(x1_,x2_) for x1_ in (x1,x2)] for x2_ in (x1,x2)]
sympy.Matrix(fhess_sym)
```




$\displaystyle \left[\begin{matrix}12 \left(x_{1} - 1\right)^{2} & -2\\-2 & 10\end{matrix}\right]$




```python
f_lambda = sympy.lambdify((x1,x2),f_sym,'numpy')
fprime_lambda = sympy.lambdify((x1,x2),fprime_sym,'numpy')
fhess_lambda = sympy.lambdify((x1,x2),fhess_sym,'numpy')
```


```python
def func_XY_to_X_Y(f):
    return lambda X: np.array(f(X[0],X[1]))
f = func_XY_to_X_Y(f_lambda)
fprime = func_XY_to_X_Y(fprime_lambda)
fhess = func_XY_to_X_Y(fhess_lambda)
```


```python
x_opt = op.fmin_ncg(f,(0,0),fprime=fprime, fhess=fhess)
```

    Optimization terminated successfully.
             Current function value: -3.867223
             Iterations: 8
             Function evaluations: 10
             Gradient evaluations: 10
             Hessian evaluations: 8



```python
x_opt
```




    array([1.88292613, 1.37658523])




```python
fig, ax = plt.subplots(figsize=(6,4))
x_ = y_ = np.linspace(-1,4,100)
X,Y = np.meshgrid(x_,y_)
c = ax.contour(X,Y,f_lambda(X,Y),50)
ax.plot(x_opt[0],x_opt[1],'r*',markersize=15)
ax.set_xlabel(r'$x_1$',fontsize=15)
ax.set_ylabel(r'$x_2$',fontsize=15)
plt.colorbar(c,ax=ax)
fig.savefig('duomubiao.pdf')
```


​    
![](https://img.imgdb.cn/item/6011add63ffa7d37b35cee99.jpg)
​    


前述用牛顿法处理的问题也可用bfgs和cg方法来求解，此时不需要知道Hessian函数


```python
x_opt = op.fmin_bfgs(f,(0,0),fprime=fprime)
```

    Optimization terminated successfully.
             Current function value: -3.867223
             Iterations: 9
             Function evaluations: 13
             Gradient evaluations: 13



```python
x_opt
```




    array([1.88292645, 1.37658596])




```python
x_opt = op.fmin_cg(f,(0,0),fprime=fprime)
```

    Optimization terminated successfully.
             Current function value: -3.867223
             Iterations: 8
             Function evaluations: 18
             Gradient evaluations: 18



```python
x_opt
```




    array([1.88292612, 1.37658523])



使用bfgs法时也可以不提供偏导数fprime，这样做方便但是计算次数会增加


```python
x_opt = op.fmin_bfgs(f,(0,0))
```

    Optimization terminated successfully.
             Current function value: -3.867223
             Iterations: 9
             Function evaluations: 39
             Gradient evaluations: 13



```python
x_opt
```




    array([1.88292644, 1.37658595])



上述方法必须给定起始点，得到起始点附近的局部最优解，但有时函数会有多个局部最优解，这样就很难求得全局解。这时可以用brute先进行暴搜，搜出这个大区间的最优解，再去用上述的方法得到该点附近的局部最优解。这个解通常就是这个大区间内全局最优解。


```python
def f(X):
    x,y = X
    return (4 * np.sin(x * np.pi) + 6 * np.sin(y * np.pi) + (x - 1)**2 + (y - 1)**2)
x_start = op.brute(f,(slice(-3,5,0.5),slice(-3,5,0.5)),finish=None)    #finish=None可阻止brute方法对结果的自动优化
x_start
```




    array([1.5, 1.5])




```python
f(x_start)
```




    -9.5




```python
x_opt = op.fmin_bfgs(f,x_start)
```

    Optimization terminated successfully.
             Current function value: -9.520229
             Iterations: 4
             Function evaluations: 21
             Gradient evaluations: 7



```python
x_opt
```




    array([1.47586906, 1.48365787])




```python
f(x_opt)
```




    -9.520229273055016




```python
def func_X_Y_to_XY(f,X,Y):
    s = np.shape(X)
    return f(np.vstack([X.ravel(),Y.ravel()])).reshape(*s)
fig,ax = plt.subplots(figsize=(6,4))
x_ = y_ = np.linspace(-3,5,100)
X,Y = np.meshgrid(x_,y_)
c = ax.contour(X,Y,func_X_Y_to_XY(f,X,Y),25)
ax.plot(x_opt[0],x_opt[1],'r*',markersize=15)
ax.set_xlabel(r'$x_1$',fontsize=18)
ax.set_ylabel(r'$x_2$',fontsize=18)
plt.colorbar(c, ax=ax)
fig.savefig('wqduobianliang.pdf')
```


​    
![](https://img.imgdb.cn/item/6011add73ffa7d37b35ceef4.jpg)
​    


非线性最小二乘问题可以用op.leastsq来解决

下面考虑如下优化问题
$$
f(x,\beta)=\beta_0+\beta_1 e^{-\beta_2 x^2}
$$
这里令$\beta_1=0.25,\beta_2=0.75,\beta_3=0.5$，并引入噪声作为观测数据。


```python
beta = (0.25,0.75,0.5)
def f(x,b0,b1,b2):
    return b0 + b1 * np.exp(-b2 * x**2)
xdata = np.linspace(0,5,50)
y = f(xdata, *beta)
ydata = y + 0.05 * np.random.randn(len(xdata))

def g(beta):
    return ydata - f(xdata, *beta)

beta_start = (1,1,1)
beta_opt, beta_cov = op.leastsq(g,beta_start)
beta_opt
```




    array([0.27224087, 0.73379014, 0.49448114])



可以看到拟合效果很棒，下面进行可视化


```python
fig,ax = plt.subplots()
ax.scatter(xdata,ydata, label='samples')
ax.plot(xdata,y, 'r', lw=2, label='true model')
ax.plot(xdata,f(xdata,*beta_opt), 'b', lw=2, label='fitted model')
ax.set_xlabel(r'$x$',fontsize=18)
ax.set_ylabel(r'$y$',fontsize=18)
ax.legend()
fig.savefig('feixianxin.pdf')
```


​    
![](https://img.imgdb.cn/item/6011add93ffa7d37b35cef86.jpg)
​    


还有更为简便的curve_fit方法求解上述问题，它是对leastsq方法的封装。


```python
beta_opt, beta_cov = op.curve_fit(f, xdata, ydata)
beta_opt
```




    array([0.27224087, 0.73379014, 0.49448114])



下面开始看有约束的优化问题

求解下述问题

$$
\min f(x)=(x_1-1)^2+(x_2-1)^2\\
x_1 \in [2,3] \\
x_2 \in [0,2]
$$


```python
def f(X):
    return (X[0] - 1)**2 + (X[1] - 1)**2
x_opt = op.minimize(f, [1,1], method='BFGS').x

bnd_x1, bnd_x2 = (2,3), (0,2)
x_cons_opt = op.minimize(f, [1,1], method='L-BFGS-B', bounds=[bnd_x1,bnd_x2]).x

fig,ax = plt.subplots(figsize=(6,4))
x_ = y_ = np.linspace(-1,3,100)
X,Y = np.meshgrid(x_,y_)
c = ax.contour(X,Y, func_X_Y_to_XY(f,X,Y),50)
ax.plot(x_opt[0],x_opt[1], 'b*', markersize=15)
ax.plot(x_cons_opt[0],x_cons_opt[1], 'r*', markersize=15)

bound_rect = plt.Rectangle((bnd_x1[0],bnd_x2[0]), bnd_x1[1]-bnd_x1[0], bnd_x2[1]-bnd_x2[0], facecolor='grey')
ax.add_patch(bound_rect)
ax.set_xlabel(r'$x$',fontsize=18)
ax.set_ylabel(r'$y$',fontsize=18)
plt.colorbar(c, ax=ax)
fig.savefig('youyueshuduobianliang.pdf')
```


​    
![](https://img.imgdb.cn/item/6011add93ffa7d37b35cefc1.jpg)
​    


利用拉格朗日乘子法可以将有约束问题转化为无约束问题


```python
x = x0,x1,x2,l = sympy.symbols('x_0, x_1, x_2, lambda')
f = x0 * x1 * x2
g = 2 * (x0*x1 + x1*x2 + x0*x2) - 1
L = f + l * g
grad_L = [sympy.diff(L, x_) for x_ in x]
sols = sympy.solve(grad_L)
sympy.Matrix(sols)
```








接下来舍去第二个驻点，验证结果。


```python
g.subs(sols[0])
```




$\displaystyle 0$




```python
f.subs(sols[0])
```




$\displaystyle \frac{\sqrt{6}}{36}$



该方法拓展后也可以求解不等式约束，称之为SLSQP

对于如上问题，我们可以如此做


```python
def f(X):
    return -(X[0] * X[1] * X[2])
def g(X):
    return 2 * (X[0]*X[1] + X[0]*X[2] + X[1]*X[2]) - 1
constraint = dict(type='eq', fun=g)
result = op.minimize(f, [0.5,1,1.5], method='SLSQP', constraints=[constraint])
result
```




         fun: -0.06804136862324839
         jac: array([-0.16666926, -0.16666542, -0.16666526])
     message: 'Optimization terminated successfully'
        nfev: 77
         nit: 18
        njev: 18
      status: 0
     success: True
           x: array([0.40824187, 0.40825127, 0.40825165])



将约束条件改为 $g(x)=x_1 - 1.75 - (x_0 - 0.75)^4 \geq 0$，研究上一个二次问题


```python
def f(X):
    return (X[0] - 1)**2 + (X[1] - 1)**2
def g(X):
    return X[1] - 1.75 - (X[0] - 0.75)**4
constraint = [dict(type='ineq', fun=g)]
x_opt = op.minimize(f,(0,0),method='BFGS').x
x_cons_opt = op.minimize(f,(0,0), method='SLSQP', constraints=constraint).x
```

为验证正确性进行可视化


```python
x_ = y_ = np.linspace(-1,3,100)
X,Y = np.meshgrid(x_,y_)

fig,ax = plt.subplots(figsize=(6,4))
c = ax.contour(X,Y,func_X_Y_to_XY(f,X,Y),50)
ax.plot(x_opt[0],x_opt[1], 'b*', markersize=15)
ax.plot(x_cons_opt[0],x_cons_opt[1], 'r*', markersize=15)
ax.plot(x_,1.75+(x_ - 0.75)**4, 'k-', markersize=15)
ax.fill_between(x_,1.75+(x_ - 0.75)**4, 3, color='grey')
ax.set_ylim(-1,3)
ax.set_xlabel(r'$x$', fontsize=18)
ax.set_ylabel(r'$y$', fontsize=18)
plt.colorbar(c,ax=ax)
fig.savefig('budengshiduobianliangyouhua.pdf')
```


​    
![](https://img.imgdb.cn/item/6011aded3ffa7d37b35cfa29.jpg)
​    


只有不等式约束的模型也可用COBYLA方法求解。

下面研究简单的线性规划问题


```python
c = np.array([-1.0,2.0,-3.0])
A = np.array([[1.0,1.0,0.0],[-1.0,3.0,0.0],[0.0,-1.0,1.0]])
b = np.array([1.0,2.0,3.0])
A_ = cvxopt.matrix(A)
b_ = cvxopt.matrix(b)
c_ = cvxopt.matrix(c)

sol = cvxopt.solvers.lp(c_, A_, b_)
```

    Optimal solution found.



```python
sol
```




    {'x': <3x1 matrix, tc='d'>,
     'y': <0x1 matrix, tc='d'>,
     's': <3x1 matrix, tc='d'>,
     'z': <3x1 matrix, tc='d'>,
     'status': 'optimal',
     'gap': 0.0,
     'relative gap': 0.0,
     'primal objective': -10.0,
     'dual objective': -10.0,
     'primal infeasibility': 0.0,
     'primal slack': -0.0,
     'dual slack': 0.0,
     'dual infeasibility': 1.4835979218054372e-16,
     'residual as primal infeasibility certificate': None,
     'residual as dual infeasibility certificate': None,
     'iterations': 0}




```python
x = np.array(sol['x'])
x
```




    array([[0.25],
           [0.75],
           [3.75]])




```python
sol['primal objective']
```




    -10.0


